
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<head>

  <title>Yu Sha's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Yu Sha is currently a PhD candidate at Xidian University">
  <meta name="keywords" content="Yu Sha, Ê≤ôÊØì, Sha Yu, ShaYu, shayu, ,yusha, Yu Sha FIAS, Yu Sha XDU, YU SHA, Deep Learning, Fault Detection, Cavitation, Cavitation Detection, Cavitation Intensity Recognition, Á©∫Âåñ, Á©∫ÂåñÊ£ÄÊµã, Á©∫ÂåñÂº∫Â∫¶ËØÜÂà´,Ë•øÂÆâÁîµÂ≠êÁßëÊäÄÂ§ßÂ≠¶Ê≤ôÊØìÔºåÂÖ∞Â∑ûÁêÜÂ∑•Â§ßÂ≠¶Ê≤ôÊØìÔºåHierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems
    Hierarchical Cavitation Intensity Recognition Using Sub-Master Transition Network-based Acoustic Signals in Pipeline SystemsÔºåRegional-Local Adversarially Learned One-Class Classifier Anomalous Sound Detection in Global Long-Term SpaceÔºå
    A multi-task learning for cavitation detection and cavitation intensity recognition of valve acoustic signalsÔºåAn acoustic signal cavitation detection framework based on XGBoost with adaptive selection feature engineeringÔºå
  ">
  <meta name="author" content="Yu Sha" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="figs/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->
</head>


<body class="w3-content" style="max-width:1500px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-gray w3-gray w3-collapse w3-top w3-right" style="z-index:3;width:164px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>üßë‚ÄçüéìYu</b></h3>
  </div>
<!-- Sidebar/menu -->
<div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
  <a href="#home" class="w3-bar-item w3-button">üè° Home</a>
  <a href="#news" class="w3-bar-item w3-button">üì∞ News</a>
  <a href="#researches" class="w3-bar-item w3-button">üîç Researches</a>
  <a href="#experiences" class="w3-bar-item w3-button">üíº Experiences</a>
  <a href="#educations" class="w3-bar-item w3-button">üìñ Educations</a>
  <a href="#publications" class="w3-bar-item w3-button">üìö Publications</a>
  <a href="#projects" class="w3-bar-item w3-button">üß∞ Projects</a>
  <a href="#award" class="w3-bar-item w3-button">üèÜ Awards</a>
</div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Yu</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>‚â°</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:157px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
<div class="w3-container w3-center w3-padding-32" id="home">
  <img style="width: 100%;max-width: 320px" alt="profile photo" src="figs/YuSha.jpg">
    <h1>Yu Sha</h1>
    <p class="w3-center">
      üè´ Xidian University | üìç Xi'an, China
    </p>
    <p class="w3-center">
      üá®üá≥‚ùÑÔ∏è| ‚ôÇÔ∏è | 9Ô∏è‚É£6Ô∏è‚É£ | üê≠ | ‚ôä 
    </p>
    <p class="w3-center">
     üí™ | üì∏ | üèì 
    </p>
      <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:750px">
        I am Yu Sha (ü¶àÊ≤ôÊØìü¶à), now a PhD candidate at <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University</a>, where I was co-advised by Prof. <a style="color: #447ec9" href="https://faculty.xidian.edu.cn/GSP2/zh_CN/index/335507/list/index.htm">Shuiping Gou</a></a>
        and Prof. <a style="color: #447ec9" href="https://web.xidian.edu.cn/liubo/index.html">Bo Liu</a></a>. My research interests includes AI in Industry (especially AI for acoustic damage detection and diagnosis, etc.), 
        AI in Physics (especially traditional filters with deep learning), Signal Processing and Deep Learning (especially generative models and attention mechanisms). During 2020 to 2022, I am a PhD vising student in <a style="color: #447ec9" href = "https://www.fias.science/en/theoretical-sciences/research-groups/kai-zhou/">"Deepthinkers"</a> group at 
        <a style="color: #447ec9" href="https://fias.institute/en/">Frankfurt Institute for Advanced Studies (FIAS)</a>, where I was co-advised by Prof. <a style="color: #447ec9" href="https://www.fias.science/en/fellows/detail/stoecker-horst/">Horst St√∂cker</a></a> 
        and Prof. <a style="color: #447ec9" href="https://www.fias.science/en/fellows/detail/zhou-kai/">Kai Zhou</a></a>. Before that, I received the B.Sc degree from <a style="color: #447ec9" href="https://www.lut.edu.cn/">Lanzhou University of Technology</a> in 2019.
      </p>
      <p class="w3-center">
        <a href="mailto:yusha@stu.xidian.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i>Email</a> &nbsp/&nbsp
        <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=e5ng8m0AAAAJ"><i class="fas fa-fw fa-graduation-cap"></i>Google Scholar</a> &nbsp/&nbsp
        <a href="https://orcid.org/0000-0003-4521-2077"><i class="fa fa-fw fa-address-card" aria-hidden="true"></i>ORCID</a>&nbsp/&nbsp
      </p>
      </tbody></table>
  </div>

<!-- The News Section -->
<div class="w3-container w3-padding-32" id="news">
  <h2>üì∞ News</h2>
  <div id="news-list-container">
    <ul id="news-list">
  <p>
    <p><li> <em>19/08/2024</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/expert-systems-with-applications">Expert Systems with Applications (ESWA)</a>.</li></p>
    <p><li> <em>17/05/2024</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://kdd2024.kdd.org/">ACM SIGKDD 2024 (CCF-A)</a>.</li></p>
    <p><li> <em>16/08/2023</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://link.springer.com/journal/11633">Machine Intelligence Research</a>.</li></p>
    <p><li> <em>01/12/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/artificial-intelligence-in-geosciences">Artificial Intelligence in Geosciences (AIG)</a>.</li></p>
    <p><li> <em>30/09/2022</em>, üì¢üì¢ I came back to <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University (XDU)</a> as a PhD visiting student.</li></p>
    <p><li> <em>01/08/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://opg.optica.org/conference.cfm?meetingid=63&yr=2022">Digital Holography and Three-Dimensional Imaging 2022</a>.</li></p>
    <p><li> <em>19/05/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://kdd.org/kdd2022/">ACM SIGKDD 2022 (CCF-A)</a>.</li></p>
    <p><li> <em>19/04/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence">Engineering Applications of Artificial Intelligence (EAAI)</a>.</li></p>
    <p><li> <em>06/04/2022</em>, üöÄüöÄ one paper has been uploaded to <a style="color: #447ec9" href="https://arxiv.org/">arXiv</a>.</li></p>
    <p><li> <em>01/03/2022</em>, üöÄüöÄ two papers have been uploaded to <a style="color: #447ec9" href="https://arxiv.org/">arXiv</a>.</li></p>
    <p><li> <em>10/02/2022</em>, üéâüéâ one paper has been accepted by <a style="color: #447ec9" href="https://www.sciencedirect.com/journal/measurement">Measurement</a>.</li></p>
    <p><li> <em>30/09/2020</em>, üì¢üì¢ I went to <a style="color: #447ec9" href="https://fias.institute/en/">Frankfurt Institute for Advanced Studies (FIAS)</a> as a PhD visiting student.</li></p>
    <p><li> <em>10/09/2019</em>, üì¢üì¢ I was admitted to <a style="color: #447ec9" href="https://www.xidian.edu.cn/">Xidian University (XDU)</a> as a Fast-Track PhD student.</li></p>
</div>
</div>



<!-- The Researches Section -->
<!-- class="w3-container w3-light-grey w3-padding-32" -->
<div class="w3-container w3-padding-32" id="researches">
  <h2>üîç Researches</h2>
  <!-- <ul>
      <li><strong>Analysis of battlefield situation of artificial intelligence in the context of big data</strong></li>
  </ul> -->
  <ul>

    <li><h5>AI in Industry</h5>
      <ul>
        <li>Supervised learning for acoustic damage detection and diagnosis [<a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0263224122001798">1</a>, <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0952197622001361">2</a>, <a style="color: #447ec9" href="https://arxiv.org/pdf/2203.01429.pdf ">3</a>];</li>
        <li>Unsupervised learning for acoustic signal anomalous sound detection [<a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">4</a>].</li>
      </ul>
    </li>

    <li><h5>AI in Physics</h5>
      <ul>
        <li>Traditional filters combined with deep learning [<a style="color: #447ec9" href="https://arxiv.org/abs/2105.03824">5</a>, <a style="color: #447ec9" href="https://arxiv.org/abs/2010.00985">6</a>, <a style="color: #447ec9" href="https://arxiv.org/abs/2107.00645">7</a>];</li>
        <li>Deep learning based fluid dynamics [<a style="color: #447ec9" href="https://www.pnas.org/doi/10.1073/pnas.2101784118">8</a>, <a style="color: #447ec9" href="https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/deep-learning-in-fluid-dynamics/F2EDDAB89563DE5157FC4B8342AD9C70#">9</a>].</li>
      </ul>
    </li>

    <li><h5>AI in Medicine / Biology</h5>
      <ul>
        <li>Signal-based knee disease diagnosis [<a style="color: #447ec9" href="https://link.springer.com/article/10.1007/s00500-021-06134-0">10</a>];</li>
        <li>Drug molecule generation [<a style="color: #447ec9" href="https://wires.onlinelibrary.wiley.com/doi/10.1002/wcms.1581">11</a>].</li>
      </ul>
    </li>

    <li><h5>Deep Learning</h5>
      <ul>
        <li>Generative models, eg: GAN [<a style="color: #447ec9" href="https://arxiv.org/abs/1406.2661">12</a>], Flow Models [<a style="color: #447ec9" href="https://arxiv.org/abs/1807.03039">13</a>] and Diffusion Models [<a style="color: #447ec9" href="https://arxiv.org/abs/2105.05233">14</a>, <a style="color: #447ec9" href="https://arxiv.org/abs/1503.03585">15</a>, <a style="color: #447ec9" href="https://arxiv.org/abs/2006.11239">16</a>], etc [<a style="color: #447ec9" href="https://arxiv.org/abs/2302.04265">17</a>, <a style="color: #447ec9" href="https://arxiv.org/abs/2209.11178">18</a>];</li>
        <li>Attention mechanisms, eg: Channel Attention [<a style="color: #447ec9" href="https://arxiv.org/abs/1709.01507">19</a>], Spatial Attention [<a style="color: #447ec9" href="https://arxiv.org/abs/1807.06521">20</a>] and Physical Attention [<a style="color: #447ec9" href="https://arxiv.org/abs/2012.11879">21</a>].</li>
      </ul>
    </li>
  </ul>
</div>

<!-- The Experiences Section -->
<div class="w3-container w3-padding-32" id="experiences">
  <h2>üíº Experiences</h2>
    <p><li> <em>09/2019 - now</em>, <strong>PhD Student</strong>, School of Artificial Intelligence, Xidian University (XDU), China.</li></p>
    <p><li> <em>09/2020 - 10/2022</em>, <strong>PhD Vising Student</strong>, Xidian-FIAS Joint Research Center (XFJRC), Germany.</li></p>
    <p><li> <em>09/2020 - 10/2022</em>, <strong>PhD Vising Student</strong>, Frankfurt Institute for Advanced Studies (FIAS), Germany.</li></p>
</div>

<!-- The Educations Section -->
<div class="w3-container w3-padding-32" id="educations">
  <h2>üìñ Educations</h2>
    <p><li> <em>09/2019 - now</em>, School of Artificial Intelligence, Xidian University (XDU), China.</li></p>
    <p><li> <em>09/2015 - 06/2019</em>, School of Science, Lanzhou University of Technology (LUT), China.</li></p>
</div>

<!-- The Publications Section -->
<div class="w3-container w3-padding-32"" id="publications">
  <h2>üìö Publications</h2>
    <!-- <p class="w3-left-align" style="line-height:200%">
    I'm interested in devleoping <strong>efficient models</strong> for computer vision (e.g. classification, detection, and super-resolution) using pruning, quantization, distilaltion, NAS, etc.
    </p> -->
      <h4> Papers:</h4>
      <ol>
        <!-- 11 -->
        <div class="container">
          <div style="display: flex; align-items: flex-start; position: relative;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    KDD 2024 (oral)
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/KDD2024.png' alt="sym" width="400" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Hierarchical Knowledge Guided Fault Intensity Diagnosis of Complex Industrial Systems</strong>
                <br>
                <strong>Yu Sha</strong>, Shuiping Gou, Bo Liu, Ningtao Liu, Johannes Faber, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou  
                <br>
                <em><strong>SIGKDD 2024</strong></em> | <strong>CCF: A</strong> |
                <a style="color: #447ec9" href="https://doi.org/10.1145/3637528.3671610">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/HKG">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper explores hierarchical Knowledge of labels with GCN.</li>
                <li style="margin-left: 10px;">The paper presents the Hierarchical Knowledge Correlation Matrix.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 10 -->
          <!-- ÈöêÂΩ¢ÁôΩÁ∫ø -->
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    ESWA 2024
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/ESWA2024.png' alt="sym" width="400" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Hierarchical Cavitation Intensity Recognition Using Sub-Master Transition Network-based Acoustic Signals in Pipeline Systems</strong>
                <br>
                Shuiping Gou, <strong>Yu Sha*</strong>, Bo Liu, Ningtao Liu, Johannes Faber, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou (If you know, you know)  
                <br>
                <em><strong>Expert Systems with Applications</strong></em> | 2024 |<strong>SCI: 1-Top</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0957417424020220?via%3Dihub">Paper</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper presents a two-stage hierarchical classification network</li>
                <li style="margin-left: 10px;">The paper proposes a hierarchical label tree.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>
        </div>

        <!-- 9 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    KDD 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/KDD2022.png' alt="sym" width="400" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Regional-Local Adversarially Learned One-Class Classifier Anomalous Sound Detection in Global Long-Term Space</strong>
                <br>
                <strong>Yu Sha</strong>, Shuiping Gou, Johannes Faber, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou  
                <br>
                <em><strong>SIGKDD 2022</strong></em> | <strong>CCF: A</strong> |
                <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/GRLNet">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a global filter layer based on a 1D FFT global filter for long-term interactions.</li>
                <li style="margin-left: 10px;">The paper extends the capability of discriminating real against fake signals to differentiating between local and regional reconstructions.</li>
                <li style="margin-left: 10px;">The paper designs a novel balanceable detection strategy.</li>
              </ul>
            </div>
          </div>

        <!-- 8 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    EAAI 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/EAAI2022.png' alt="sym" width="400" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>A multi-task learning for cavitation detection and cavitation intensity recognition of valve acoustic signals</strong>
                <br>
                <strong>Yu Sha</strong>, Johannes Faber, Shuiping Gou, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou 
                <br>
                <em><strong>Engineering Applications of Artificial Intelligence</strong></em> | 2022 | <strong>SCI: 2-Top</strong> |
                <a style="color: #447ec9" href="https://dl.acm.org/doi/abs/10.1145/3534678.3539133">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/GRLNet">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper regards cavitation detection and cavitation intensity recognition as a multi-task learning.</li>
                <li style="margin-left: 10px;">The 1-D Double Hierarchical Residual Blocks with large kernel are proposed as an automatic feature extractor.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 7 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    Measurement 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/Measurement2022.png' alt="sym" width="400" height="220" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>An acoustic signal cavitation detection framework based on XGBoost with adaptive selection feature engineering</strong>
                <br>
                <strong>Yu Sha</strong>, Johannes Faber, Shuiping Gou, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou
                <br>
                <em><strong>Measurement</strong></em> | 2022 | <strong>SCI: 2-Top</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S0263224122001798">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/CavitationDetection/XGBoost_ASFE">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a adaptive feature aggregation module.</li>
                <li style="margin-left: 10px;">The paper presents a adaptive feature crosses module.</li>
                <li style="margin-left: 10px;">The sound cavitation datasets provided by SAMSON AG.</li>
              </ul>
            </div>
          </div>

        <!-- 6 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    MIR 2023
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/MIR2023.png' alt="sym" width="400" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Prioritization Hindsight Experience based on Spatial Position Attention for Robots</strong>
                <br>
                Ye Yuan, <strong>Yu Sha</strong>, Feixiang Sun, Haofan Lu, Shuiping Gou, Jie Luo (If you know, you know)
                <br>
                <em><strong>Machine Intelligence Research</strong></em> | 2023 | <strong>SCI: 4</strong> |
                <a style="color: #447ec9" href="https://link.springer.com/journal/11633">Paper</a> | 
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a spatial position attention module for the existing HER framework.</li>
                <li style="margin-left: 10px;">The paper presents a theoretical analysis of the total spatial position distance of manipulated object.</li>
                <li style="margin-left: 10px;">Eight robotic manipulation tasks in the Fetch and Hand robot environments of OpenAI Gym.</li>
              </ul>
            </div>
          </div>

        <!-- 5 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    DH3D 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/DH3D2022.png' alt="sym" width="400" height="150" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>Phase Retrieval for Terahertz Holography with Physics-Informed Deep Learning</strong>
                <br>
                Mingjun Xiang, Lingxiao Wang, <strong>Yu Sha</strong>, Hui Yuan, Kai Zhou, Hartmut G Roskos
                <br>
                <em><strong>Digital Holography and Three-Dimensional Imaging</strong></em> | 2022 | <strong>EI</strong> |
                <a style="color: #447ec9" href="https://link.springer.com/journal/11633">Paper</a>  
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">The paper proposes a two novel phase retrieval methods for THz holography.</li>
                <li style="margin-left: 10px;">The paper employs unsupervised learning and supervised learning based on the MNIST dataset.</li>
              </ul>
            </div>
          </div>
        
        <!-- 4 -->
        <div class="container">
          <div style="height: 20px; background-color: white;"></div>
          <div style="display: flex; align-items: flex-start; position: relative; margin-top: 20px;">
            <!-- ÂõæÂÉèÈÉ®ÂàÜ -->
            <div style="flex: 1; position: relative;">
              <div class='paper-box-image'>
                <div style="position: relative;">
                  <!-- Badge ËÆæÁΩÆ‰∏∫ÁªùÂØπÂÆö‰ΩçÔºåÂπ∂Ê∑ªÂä†ËìùËâ≤ËÉåÊôØ -->
                  <div class="badge" style="position: absolute; top: 1px; left: 1px; background-color: rgb(218, 60, 152); color: white; padding: 5px 10px; border-radius: 5px;">
                    AIIG 2022
                  </div>
                  <!-- ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ -->
                  <img src='figs/AIIG2022.png' alt="sym" width="400" height="180" style="box-shadow: 3px 3px 6px #888;">
                </div>
              </div>
            </div>
        
            <!-- ÊñáÊú¨ÈÉ®ÂàÜ -->
            <div style="flex: 2; padding-left: 20px;">
              <li>
                <strong>A study on small magnitude seismic phase identification using 1D deep residual neural network</strong>
                <br>
                Wei Li, Megha Chakraborty, <strong>Yu Sha</strong>, Kai Zhou, Johannes Faber, Georg R√ºmpker, Horst St√∂cker, Nishtha Srivastava
                <br>
                <em><strong>Artificial Intelligence in Geosciences</strong></em> | 2022 | <strong>SCI: 2</strong> |
                <a style="color: #447ec9" href="https://www.sciencedirect.com/science/article/pii/S2666544122000284">Paper</a> | 
                <a style="color: #447ec9" href="https://github.com/srivastavaresearchgroup/Seismic-phase-Classification">Code</a>
              </li>
              
              <!-- ‰ΩøÁî®Êó†Â∫èÂàóË°®ÂíåÂÆûÂøÉÂ∫èÂè∑ -->
              <ul style="list-style-type: disc; margin: 10px 0 0 20px; padding-left: 0;">
                <li style="margin-left: 10px;">1D deep Residual Neural Network for tackling the problem of seismic signal detection and phase identification.</li>
                <li style="margin-left: 10px;">The method is trained and tested on the dataset recorded by the Southern California Seismic Network.</li>
                <li style="margin-left: 10px;">The model generalizability is also tested further on the STanford EArthquake Dataset.</li>
              </ul>
            </div>
          </div>
        

        <!-- 3 -->
        <p>
          <li><strong>Deep Learning-based Small Magnitude Earthquake Detection and Seismic Phase Classification</strong>
          <br>
          Wei Li, <strong>Yu Sha</strong>, Kai Zhou, Johannes Faber, Georg R√ºmpker, Horst St√∂cker, Nishtha Srivastava
          <br>
          <em>arXiv</em> 2204.02870 | <a style="color: #447ec9" href="https://arxiv.org/pdf/2204.02870.pdf">Paper</a> | <a style="color: #447ec9" href="https://github.com/srivastavaresearchgroup/Seismic-phase-Classification">Code</a>
        </p>

        <!-- 2 -->
        <p>
          <li><strong>Smart home system based on STC89C52</strong>
          <br>
          Liang Qin, <strong>Yu Sha</strong>, Yumeng Xu
          <br>
          <em>Practical Electronics</em> | 2018 | <a style="color: #447ec9" href="http://www.cqvip.com/qk/97913x/201803/674492691.html">Paper</a>
        </p>

        <!-- 1 -->
        <p>
          <li><strong>Study on operation analysis and decision making for sharing-bicycles</strong>
          <br>
          Hong Zhang, Dixin Zhou, Chuanqi Cheng, <strong>Yu Sha</strong> 
          <br>
          <em>Big Data Research</em> | 2019 | <a style="color: #447ec9" href="http://www.infocomm-journal.com/bdr/CN/Y2019/V5/I1/87">Paper</a>
        </p>
      </ol>

    <h4> Patents:</h4>
    <ol>
      <p>
        <li><strong>Heart rate estimation method based on cross-modal mapping of heart impact map signals</strong>
        <br>
        Shuiping Gou, Yuanjie Liu, Ningtao Liu, <strong>Yu Sha</strong>, Changzhe Jiao, Dong Hai, Shasha Mao, Jiaxin Cheng
        <br>
        <em>Invention Patent</em> | CN111887858B | </a>
      </p>
      
      <p>
        <li><strong>Hierarchical Cavitation Intensity Recognition Using Sub-Master Transition Network-based Acoustic Signals in Pipeline Systems</strong>
        <br>
        Shuiping Gou, <strong>Yu Sha</strong>, Zhang Guo, Bo Liu
        <br>
        <em>Invention Patent</em> | 202310945885.1 | </a>
      </p>
      
      <p>
        <li><strong>Face Aging Method Based on Adversarial Learning of Local and Global Region Policies</strong>
        <br>
        Shuiping Gou, Ruichen Xue, Nuo Tong, Ruimin Li, <strong>Yu Sha</strong>, Ningtao Liu
        <br>
        <em>Invention Patent</em> | 202310941541.3 |</a>
      </p>
      
    </ol>
</div>

<!-- The Projects Section -->
<div class="w3-container w3-padding-32" id="projects">
  <h2>üß∞ Projects</h2>
  <h4> Xidian University (XDU):</h4>
  <ol>
    <p>
      <li><strong>Analysis of battlefield situation of artificial intelligence in the context of big data</strong>
      <br>
      <em>The 20th Research Institute of China Electronics Technology Group Corporation-Xidian Joint Laboratory for Artificial Intelligence</em> | <strong>Under Study</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>Knee intensity recognition for smart wearable devices based on machine learning</strong>
      <br>
      <em>Xijing Hospital</em> | <strong>Under Study</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>

  <h4>Frankfurt Institute for Advanced Studies (FIAS):</h4>
  <ol>
    <p>
      <li><strong>Cavitation and leakage detection in large pump/pipe using AI method</strong>
      <br>
      <em>SAMSON AG</em> | <strong>Under Study</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>

  <h4>Lanzhou University of Technology (LUT):</h4>
  <ol>
    <p>
      <li><strong>LoRa based non-contact life detection system</strong>
      <br>
      <em>National Undergraduate Innovation and Entrepreneurship Training Project</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>Evaluation of students' comprehensive ability and program design based on fuzzy theory</strong>
      <br>
      <em>LUT Innovation and Entrepreneurship Training Program</em> | <strong>Completed</strong> | <strong>Project Leader</strong>
      <br>    
    </p>

    <p>
      <li><strong>Research on the cultivation of college students' creative ability by mathematical modeling competition</strong>
      <br>
      <em>LUT Technology Innovation Fund</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>

    <p>
      <li><strong>WeChat program design for second-hand transaction and donation platform on campus</strong>
      <br>
      <em>LUT Technology Innovation Fund</em> | <strong>Completed</strong> | <strong>Project Participant</strong>
      <br>    
    </p>
  </ol>
  
<!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>üèÜ Awards</h2>
    <h4> Xidian University (XDU):</h4>    
    <p><li> <em>2022</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2022</em>, Graduate Student Academic Scholarships (First Level), XDU</p>
    <p><li> <em>2021</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2021</em>, Graduate Student Academic Scholarships (Second Level), XDU</p>
    <p><li> <em>2021</em>, OGB Large-Scale Challenge, KDD Cup 2021, Team Name: <strong>yfishlab</strong>, World Ranking: <strong>Top 48</strong></p>
    <p><li> <em>2020</em>, Outstanding Doctoral Students, XDU</p>
    <p><li> <em>2020</em>, Graduate Student Academic Scholarships (Second Level), XDU</p>
    <p><li> <em>2020</em>, ZhiPu AI: COVID-19 Prediction, <strong>Top 7</strong>
    <p><li> <em>2020</em>, iFLYTEK Algorithm Competition: Temperature Prediction Challenge, Team Name: <strong>San Ren Xing</strong>, <strong>Top 5</strong>, </p>

    <h4> Lanzhou University of Technology Technology (LUT):</h4>
    <p><li> <em>2019</em>, Outstanding Graduates Awards, LUT</p>
    <p><li> <em>2018</em>, Meritorious Winner of Mathematical Contest in Modeling (MCM/ICM)</p>
    <p><li> <em>2018</em>, First Prize in the 8th MathorCup College Student Mathematical Modeling Challenge</p>
    <p><li> <em>2018</em>, First Prize in the 6th Teddy Cup Data Mining Challenge Competition</p>
    <p><li> <em>2018</em>, Pacemaker to Merit Student, LUT</p>
    <p><li> <em>2017</em>, First Prize of 2017 China Cup ¬∑ Science and Technology Innovation Contest</p>
    <p><li> <em>2017</em>, Second Prize in 2017 Asia and Pacific Mathematical Contest in Modeling</p>
    <p><li> <em>2017</em>, First Prize of Gansu Division in 2017 National College Mathematical Modeling Contest of Higher Education Cup</p>
    <p><li> <em>2017</em>, Third Prize in the 7th MathorCup College Student Mathematical Modeling Challenge</p>
    <p><li> <em>2017</em>, Merit Student, LUT</p>
    <p><li> <em>2017</em>, Merit Student, Gansu Province</p>
    <p><li> <em>2017</em>, National Encouragement Scholarship</p>
    <p><li> <em>2016</em>, National Encouragement Scholarship</p>
  </div>  

<div class="w3-light-grey w3-center w3-padding-24">

  No.
  <script type="text/javascript">
  var sc_project=12881779; 
  var sc_invisible=0; 
  var sc_security="9a565db4"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since May 2023. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript><div class="statcounter"><a title="Web Analytics Made Easy - StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12881779/0/9a565db4/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
